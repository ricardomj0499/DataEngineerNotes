# 游냊 Big Data Cluster con Hadoop, HDFS, YARN, Trino, Hive, Delta Lake y Kafka

Este proyecto te permite construir un **cl칰ster Big Data completo** desde cero usando **Docker**, empezando por Hadoop y expandi칠ndose progresivamente con otras herramientas como **Trino**, **Hive Metastore**, **Delta Lake** y **Kafka**. Est치 pensado para aprender profundamente c칩mo funciona cada componente, incluyendo **configuraci칩n manual, autenticaci칩n, usuarios y red entre nodos**.

---

## 游 Tecnolog칤as involucradas

- [x] Hadoop 3.x (HDFS + YARN)
- [ ] Trino (SQL engine)
- [ ] Hive Metastore
- [ ] Delta Lake (con soporte Parquet)
- [ ] Apache Kafka
- [ ] Cliente externo (WSL2 o cualquier m치quina externa)
- [ ] Autenticaci칩n y gesti칩n de usuarios (Kerberos, LDAP, o personalizada)

---

## 游 Objetivo

> Crear un cl칰ster donde cada componente se instale y configure manualmente dentro de contenedores, permitiendo:
- Aprender a instalar Hadoop y amigos **desde cero**
- Controlar la red y los puertos entre contenedores
- Simular un entorno de producci칩n con **SSH y m칰ltiples nodos**
- Conectarte desde una m치quina externa (cliente WSL2)
- Enfrentar problemas reales como **autenticaci칩n**, **usuarios**, **conexiones distribuidas**, etc.

---

## 游닍 Estructura del proyecto

