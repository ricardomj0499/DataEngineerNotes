# Hadoop Worker Node - Notas sobre la Construcci√≥n y Funcionamiento de la Imagen

## üõ†Ô∏è 1. Gesti√≥n de Procesos en el Contenedor

En esta imagen **no se inician autom√°ticamente los servicios de Hadoop (DataNode o NodeManager)**.

- Los servicios son inicializados desde el nodo master utilizando los comandos:

```bash
start-dfs.sh
start-yarn.sh
```

- Este enfoque simula un entorno real donde existe un servidor maestro que controla el inicio de servicios en los workers.

### ‚ö†Ô∏è Implicaci√≥n:

- Es necesario que el contenedor tenga un proceso principal corriendo para que Docker lo mantenga activo.
- Para esto, actualmente se utiliza:

```dockerfile
ENTRYPOINT ["sudo", "/usr/sbin/sshd", "-D"]
```

Esto mantiene el contenedor vivo ejecutando el servidor SSH en primer plano.

### üö´ Problema de este enfoque:

- Se rompe parcialmente la filosof√≠a de Docker de tener **un √∫nico proceso principal**.
- Cuando se inician los servicios de Hadoop (`datanode` y `nodemanager`), estos corren como procesos adicionales dentro del mismo contenedor.
- Si Docker reinicia el contenedor, **los servicios de Hadoop no se reinician autom√°ticamente**, ya que no forman parte del `ENTRYPOINT`.

### ‚úîÔ∏è Soluci√≥n propuesta (mejor pr√°ctica):

- Crear un `entrypoint.sh` que arranque tanto el servidor SSH como los daemons de Hadoop.

Ejemplo de `entrypoint.sh`:

```bash
#!/bin/bash
set -e

# Iniciar servidor SSH
sudo service ssh start

# Iniciar DataNode
echo "Starting DataNode..."
hdfs --daemon start datanode

# Iniciar NodeManager
echo "Starting NodeManager..."
yarn --daemon start nodemanager

# Mantener el contenedor en ejecuci√≥n
tail -f /dev/null
```

---

## ‚òï 2. Instalaci√≥n de Java

- En esta imagen se instala **Java 21** debido a que se planea utilizar Spark dentro del cl√∫ster.
- Spark requiere versiones m√°s modernas de Java (17 o superior en versiones recientes).

## üîê 3. Configuraci√≥n del Servidor SSH

Durante la construcci√≥n de la imagen se ejecuta:

```dockerfile
RUN sudo service ssh start && sudo ssh-keygen -A
```

### ü§î ¬øPor qu√© se hace esto?

- En pruebas realizadas, se detect√≥ que utilizar solamente:

```bash
ssh-keygen -A
```

**no era suficiente**, ya que algunas carpetas necesarias para el funcionamiento de `sshd` (como `/run/sshd`) **no eran creadas autom√°ticamente**.

### ‚úîÔ∏è Soluciones alternativas v√°lidas:

- Crear manualmente la carpeta requerida:

```dockerfile
RUN mkdir -p /run/sshd
```

- Luego ejecutar solo:

```bash
ssh-keygen -A
```

- Finalmente, iniciar el servicio SSH dentro del `entrypoint.sh` con:

```bash
sudo service ssh start
```

Esta es una forma m√°s limpia y alineada con buenas pr√°cticas en Docker.

---

## ‚úÖ Resumen de Buenas Pr√°cticas Propuestas

| Tema                 | Pr√°ctica Actual                               | Mejor Pr√°ctica Recomendada                                                                                      |
| -------------------- | --------------------------------------------- | --------------------------------------------------------------------------------------------------------------- |
| Proceso Principal    | SSH como ENTRYPOINT                           | entrypoint.sh que inicia SSH + Hadoop daemons                                                                   |
| Gesti√≥n de Servicios | Desde master con start-dfs.sh y start-yarn.sh | V√°lido, pero mejor si workers tambi√©n inician solos                                                             |
| Instalaci√≥n de Java  | Java 21                                       | ‚úÖ Correcto por compatibilidad con Spark                                                                        |
| Configuraci√≥n de SSH | ssh start en build                            | Crear /run/sshd + ssh-keygen -A en build(Aunque tengo entendido, que lo mejor es no usar ssh en estos amgiente) |

---

## üìú Ejemplo Completo de entrypoint.sh

```bash
#!/bin/bash
set -e

# Start SSH service
sudo service ssh start

# Start Hadoop DataNode
echo "Starting DataNode..."
hdfs --daemon start datanode

# Start Hadoop NodeManager
echo "Starting NodeManager..."
yarn --daemon start nodemanager

# Keep container running
tail -f /dev/null
```

---

## üöÄ Consideraciones Finales

Este dise√±o busca balancear el aprendizaje sobre c√≥mo funciona un cl√∫ster Hadoop real, incluyendo su interacci√≥n v√≠a SSH, junto con la flexibilidad de un entorno Dockerizado.

Si el objetivo evoluciona hacia mayor automatizaci√≥n o integraci√≥n con orquestadores como Kubernetes, se puede modificar la arquitectura eliminando SSH como dependencia y delegando el arranque de servicios a mecanismos de inicializaci√≥n m√°s modernos.
